---
title: "Arctic_Lake_Analysis"
author: "Simon Topp"
date: "11/23/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(mapview)
library(sf)
library(feather)
library(furrr)
library(trend)
library(tictoc)

knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
lakes <- read_csv('data/in/ArcticWaters/LakesObu_90m_wIDs_Clim.csv') %>%
  select(ID = label, pf = first, region = tcode_first, year = year_first, 
         area = area_sum, tempA = temp_amean, tempS = temp_smean, precipA = precip_amean, 
         precipS = precip_smean, .geo) %>%
  mutate(area = area/1e6,
         region = factor(region, levels = c(1:6), 
                         labels = c('Mackenzie', 'North America West', 
                                    'North America East', 'Siberia West', 'Siberia East', 'Alaska')),
         pf = factor(pf, levels = c(1:4), labels = c('Cont.', 'Discon.', 'Spora.', 'Isol')))

## Fix the geo columns
lakes <- lakes %>% 
  separate(.geo, into = c('text', 'coords'), sep = ':\\[') %>% 
  separate(coords, into = c('long', 'lat'), sep = ',') %>% 
  mutate(long = as.numeric(long), 
         lat = gsub(lat, pattern = '\\]}', replacement = ''), 
         lat = as.numeric(lat)) %>%
  select(-text)

write_feather(lakes, 'data/out/lakes_90mClim_munged.feather')
```

## Including Plots

You can also embed plots, for example:
```{r pressure, echo=FALSE}
lakes <- read_feather('data/out/lakes_90mClim_munged.feather') %>%
  filter(area < 25)

ggplot(lakes, aes(x = area)) + geom_histogram() + scale_x_continuous(trans = 'log10') +
  facet_wrap(~region, scales = 'free')

ggplot(lakes, aes(x = area, color = year, group = year)) + geom_density() +
  scale_color_viridis_c(option = 'plasma') +
  scale_x_continuous(trans = 'log10') +
  facet_wrap(~pf)
  
lakes.summ <- lakes %>%
  group_by(region, year, pf) %>%
  summarise(count = n(), 
            area = sum(area),
            ta = mean(tempA),
            ts = mean(tempS),
            pa = mean(precipA),
            ps = mean(precipS))

```


```{r}
plotter <- function(studyReg){
  areaCol <- viridis::viridis(1)
  countCol <- viridis::viridis(1, begin = .5)
  waterC <- lakes.summ %>% filter(region == studyReg & pf == 'Cont.')
  coefC <- mean(waterC$count)/mean(waterC$area)
 p1 <- ggplot(waterC, aes(x = year)) +
    #geom_smooth(aes(y = area), span = .2, color = areaCol) +
    #geom_smooth(aes(y = count/coefC), span = .2, color = countCol) + 
    geom_line(aes(y = area), color = areaCol) +
    geom_line(aes(y = count/coefC), color = countCol) + 
    scale_y_continuous(
    name = "Area (sq km)",
    sec.axis = sec_axis(~.*coefC, name="Lake Count")) +
    labs(subtitle = 'Continuous') +
    theme_bw() +
    theme(
    axis.text.y = element_text(color = areaCol),
    axis.text.y.right = element_text(color = countCol),
    axis.title.y.right = element_blank(),
    axis.title.y = element_text(color = areaCol, size=13),
    axis.title.x = element_blank())
 
  waterD <- lakes.summ %>% filter(region == studyReg & pf == 'Discon.')
  coefD <- mean(waterD$count)/mean(waterD$area)
  p2 <- ggplot(waterD, aes(x = year)) +
    #geom_smooth(aes(y = area), span = .2, color = areaCol) +
    #geom_smooth(aes(y = count/coefD), span = .2, color = countCol) + 
    geom_line(aes(y = area), color = areaCol) +
    geom_line(aes(y = count/coefD), color = countCol) + 
    scale_y_continuous(
    name = "Area (sq km)",
    sec.axis = sec_axis(~.*coefD, name="Lake Count")) +
    labs(subtitle = 'Discontinuous') +
    theme_bw() +
    theme(
    axis.text.y = element_text(color = areaCol),
    axis.text.y.right = element_text(color = countCol),
    axis.title.y = element_blank(),
    axis.title.y.right = element_blank(),
    axis.title.x = element_blank())
  
  waterS <- lakes.summ %>% filter(region == studyReg & pf == 'Spora.')
  coefS <- mean(waterS$count)/mean(waterS$area)
  p3 <- ggplot(waterS, aes(x = year)) +
    #geom_smooth(aes(y = area), span = .2, color = areaCol) +
    #geom_smooth(aes(y = count/coefD), span = .2, color = countCol) + 
    geom_line(aes(y = area), color = areaCol) +
    geom_line(aes(y = count/coefS), color = countCol) + 
    scale_y_continuous(
    name = "Area (sq km)",
    sec.axis = sec_axis(~.*coefD, name="Lake Count")) +
    labs(subtitle = 'Sporadic') +
    theme_bw() +
    theme(
    axis.text.y = element_text(color = areaCol),
    axis.text.y.right = element_text(color = countCol),
    axis.title.y = element_blank(),
    axis.title.y.right = element_blank(),
    axis.title.x = element_blank())
    
  gridExtra::grid.arrange(p1,p2,p3, nrow = 1, top = studyReg)
}
 
p1 <- plotter('Alaska')
p2 <- plotter("Mackenzie") 
p3 <- plotter("North America West")
p4 <- plotter('North America East')
p5 <- plotter( "Siberia West")
p6 <- plotter("Siberia East")

g <- gridExtra::grid.arrange(p1, p2, p3, p4, p5, p6, nrow = 6)
ggsave('figures/AreaCountsRegional.png', plot = g, width = 6.5, height = 7, units = 'in')


rm(p1,p2,p3,p4,p5,p6)


## look at the climate variables
ggplot(lakes.summ %>% filter(!is.na(pf)), aes(x = year)) +
  geom_line(aes(y = ta, color = 'Temp Annual')) + 
  geom_line(aes(y = ts, color = 'Temp Summer')) +
  facet_grid(region~pf, scales = 'free') +
  theme_bw()

ggplot(lakes.summ %>% filter(!is.na(pf)), aes(x = year)) +
  geom_line(aes(y = pa, color = 'Precip Annual')) + 
  geom_line(aes(y = ps, color = 'Precip Summer')) +
  facet_grid(region~pf, scales = 'free') +
  theme_bw()

clim.plotter <- function(v1, v2){
  ggplot(lakes.summ %>% filter(!is.na(pf)), aes_string(x = v1, y = v2)) +
    geom_point() +
    geom_smooth(method = 'lm') +
    ggpmisc:: stat_poly_eq(formula = y~x, 
              aes(label = paste(..rr.label.., sep = "~~~")), 
              parse = TRUE) +
    facet_grid(region~pf, scales = 'free')
}

clim.plotter('ts','count')

ggplot(lakes.summ %>% filter(!is.na(pf)), aes(x = pa, y = ps)) +
  geom_point() +
  facet_grid(region~pf)

acfs <- lakes.summ %>% filter(!is.na(pf)) %>% arrange(year) %>%
  group_by(region, pf) %>%
  nest() %>%
  mutate(acf = purrr:::map(data, ~ccf(x = .$area, y = .$ps, plot = F, lag.max = 5)),
         lag = purrr::map(acf, ~as.numeric(.$lag)),
         acf = purrr::map(acf, ~as.numeric(.$acf)))%>%
  select(-data) %>%
  unnest(cols = c(acf, lag)) %>%
  filter(lag > -1)

ggplot(acfs, aes(x = lag, y = acf)) +
  geom_bar(stat = 'identity')+
  facet_grid(region~pf)


```

## Look at some trends

```{r}
trends <- lakes.summ %>% filter(!is.na(pf)) %>%
  arrange(year) %>%
  group_by(region, pf) %>%
  nest() %>%
  mutate(sens.area = purrr::map(data, ~trend::sens.slope(.$area)),
         slope.area = map_dbl(sens.area, 'estimates'),
         p_area = map_dbl(sens.area, 'p.value'),
         sens.count = purrr::map(data, ~trend::sens.slope(.$count)),
         slope.count = map_dbl(sens.count, 'estimates'),
         p_count = map_dbl(sens.count, 'p.value')) %>%
  select(-c(data, sens.area, sens.count))

trends <- trends %>% 
  select(-p_count, -p_area, area = slope.area, count = slope.count) %>%
  pivot_longer(c(area, count), names_to = 'Metric', values_to = 'Slope') %>%
  left_join(
    trends %>% select(-slope.area, -slope.count, area = p_area, count = p_count) %>%
  pivot_longer(c(area, count), names_to = 'Metric', values_to = 'p.value')
  ) %>%
  mutate(sig = ifelse(p.value < 0.05, T,F))

ggplot(trends, aes(x = region, y = Slope, fill = pf, alpha = sig)) +
  geom_col(position = 'dodge') +
  scale_y_continuous(trans = 'log10') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 30, vjust = 1, hjust =1)) +
  facet_wrap(~Metric, scales = 'free')

ggplot(trends, aes(x = pf, y = Slope, fill = Metric, alpha = sig)) +
  geom_col(position = 'dodge') + 
  labs(x = 'PF Type', title = 'Sen Slopes', alpha = 'Sig. (95%)') +
  #scale_y_continuous(trans = 'log10') +
  facet_grid(~region, scales = 'free')

```

```{r}
mean.area <- lakes %>% group_by(year, region, pf) %>%
  summarise(area = median(area)) %>%
  na.omit()

ggplot(mean.area, aes(x = year, y = area, color = pf)) + 
  geom_line() + labs(x = 'Mean lake area') + facet_wrap(~region, scales = 'free')
```



## pipeline for quick examination of size-breaks
```{r}
lakes.summ <- lakes %>% filter(area > 1) %>%
  group_by(region, year, pf) %>%
  summarise(count = n(), 
            area = sum(area),
            ta = mean(tempA),
            ts = mean(tempS),
            pa = mean(precipA),
            ps = mean(precipS))

p1 <- plotter('Alaska')
p2 <- plotter("Mackenzie") 
p3 <- plotter("North America West")
p4 <- plotter('North America East')
p5 <- plotter( "Siberia West")
p6 <- plotter("Siberia East")

g <- gridExtra::grid.arrange(p1, p2, p3, p4, p5, p6, nrow = 6)


trends <- lakes.summ %>% filter(!is.na(pf)) %>%
  arrange(year) %>%
  group_by(region, pf) %>%
  nest() %>%
  mutate(sens.area = purrr::map(data, ~trend::sens.slope(.$area)),
         slope.area = map_dbl(sens.area, 'estimates'),
         p_area = map_dbl(sens.area, 'p.value'),
         sens.count = purrr::map(data, ~trend::sens.slope(.$count)),
         slope.count = map_dbl(sens.count, 'estimates'),
         p_count = map_dbl(sens.count, 'p.value')) %>%
  select(-c(data, sens.area, sens.count))

trends <- trends %>% 
  select(-p_count, -p_area, area = slope.area, count = slope.count) %>%
  pivot_longer(c(area, count), names_to = 'Metric', values_to = 'Slope') %>%
  left_join(
    trends %>% select(-slope.area, -slope.count, area = p_area, count = p_count) %>%
  pivot_longer(c(area, count), names_to = 'Metric', values_to = 'p.value')
  ) %>%
  mutate(sig = ifelse(p.value < 0.05, T,F))

ggplot(trends, aes(x = pf, y = Slope, fill = Metric, alpha = sig)) +
  geom_col(position = 'dodge') + 
  labs(x = 'PF Type', title = 'Sen Slopes', alpha = 'Sig. (95%)') +
  #scale_y_continuous(trans = 'log10') +
  facet_grid(~region, scales = 'free')
```


## Look at number of new lakes, same lakes, old lakes


```{r}

y1 <- 2000
y2 <- 2001


EnL <- function(y2){
y1 <- y2 - 1
  
l.join <- lakes %>% filter(year == y1) %>%
  group_by(ID, pf, region) %>%
  summarize(count1 = n()) %>%
  full_join(lakes %>% filter(year == y2) %>%
  group_by(ID, pf, region) %>%
  summarize(count2 = n()))

l.join[is.na(l.join)] <- 0

l.join %>%
  mutate(diff = count2 - count1,
         status = ifelse(diff == 0, 'Same', ifelse(diff > 0, 'Emergent', 'Lost'))) %>%
  group_by(status, pf, region) %>%
  summarise(lake.count = sum(diff),
            count = n()) %>%
  mutate(lake.count = ifelse(status == 'Same', count, lake.count),
         year = y2) %>%
  select(-count)
}

lake.states <- c(2001:2018) %>% map_dfr(EnL)

lake.states %>%
  filter(!is.na(pf) & status != 'Same') %>%
  mutate(lake.count = abs(lake.count)) %>%
  ggplot(., aes(x = year, y = lake.count, fill = status)) + geom_col(position = 'fill') +
  facet_grid(region~pf, scales = 'free')

```


## Figure out which lakes are show significant trends and look at where they are!!

```{r}
lakes <- read_feather('data/out/lakes_90mClim_munged.feather') %>%
  filter(area < 25)

## Make one value for each lake/year
lakes.annual <- lakes %>% group_by(ID, year) %>%
  summarise(area = sum(area),
            tempS = mean(tempS),
            precipS = mean(precipS),
            lat = mean(lat),
            long = mean(long))

## Check how many lakes we have long timeseries for:
counts <- lakes.annual %>% group_by(ID) %>%
  summarise(count = n())

## Test it all with a small sample
samp <- counts %>% filter(count > 10)

la.nested <- lakes.annual %>% ungroup() %>%
  filter(ID %in% samp$ID) %>%
  select(-lat, -long) %>%
  pivot_longer(-c(ID, year), names_to = 'Var') %>%
  arrange(year) %>%
  group_by(ID, Var) %>%
  nest() %>%
  split(., c(1:10))

trends <- tibble(ID = NA, Var = NA, estimate = NA, p.value = NA)

## This is definitely not the fastest way to do this, but it lets you keep track of whats done
## and it shouldn't overload your memory.

for(i in c(1:10)){
tic()
plan(multisession, workers = 3L)
trend.split <- la.nested[[i]] %>%
  ungroup() %>%
  mutate(mk = future_map(data, ~ {
    mod <- sens.slope(.$value)
    tibble(estimate = mod$estimates,
           p.value = mod$p.value)}, .progress = TRUE)) %>%
  select(-data) %>%
  unnest(mk)
toc()
plan(sequential)
trends <- trends %>% bind_rows(trend.split)
}

trends$estimate <- unname(trends$estimate)
write_feather(trends, 'data/out/LakeTrends.feather')
```

```{r}
lake.summaries <- lakes.annual %>%
  group_by(ID) %>%
  summarise(area = mean(area),
            tempS = mean(tempS),
            precipS = mean(precipS),
            lat = mean(lat),
            long = mean(long))

trends <- trends %>%
  left_join(lake.summaries)

sig.trends <- trends %>% filter(p.value < 0.01)

sig.trends %>% filter(Var == 'area') %>%
  ggplot(., aes(x = estimate)) + geom_density() + theme_bw() + xlim(-.01, 0.01)

ggplot(sig.trends, aes(x = estimate)) + geom_histogram()  + facet_wrap(~Var, scales = 'free')

library(ggtern)
sig.trends 
scaled.sig.trends<- trends[-1,]  %>%
  select(Var, estimate, ID) %>%
  #group_by(Var) %>%
  #mutate(estimate = scales::rescale(estimate, to = c(0,100))) %>%
  #ungroup() %>%
  pivot_wider(names_from = Var, values_from = estimate) %>%
  filter(!is.na(area)) %>%
  arrange(area) %>%
  mutate(areaH = row_number(),
         areaH = scales::rescale(areaH, c(0,100))) %>%
  arrange(tempS) %>%
  mutate(tempH = row_number(),
         tempH = scales::rescale(areaH, c(0,100))) %>%
  arrange(precipS) %>%
  mutate(precipH = row_number(),
         precipH = scales::rescale(areaH, c(0,100)))

scaled.sig.trends %>%
  ggtern(data = ., aes(x = area, y = tempS, z = precipS)) +
  geom_point() +
  theme_rgbw()

ggplot()

```

